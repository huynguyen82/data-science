{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load text\n",
    "import os\n",
    "def get_text(filename):\n",
    "    with open(filename,'r',encoding='utf8') as file:\n",
    "        return ''.join(file.readlines()).strip()\n",
    "subfolders = [ f.path for f in os.scandir('data_science/news/') if f.is_dir()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#names=[os.path.basename(iterm) for iterm in subfolders]\n",
    "text_list=[]\n",
    "text_target=[]\n",
    "files=[]\n",
    "for dir in subfolders:    \n",
    "    for filename in os.listdir(dir):\n",
    "        if filename.endswith(\".txt\"): \n",
    "            text_target.append(int(os.path.basename(dir)))\n",
    "            text_list.append(get_text(dir + '/' + filename))\n",
    "            files.append(dir + '/' + filename)\n",
    "        else:\n",
    "            continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "text_target=np.array(text_target)\n",
    "#text_list=text_list[:,np.newaxis]\n",
    "#print(text_target.shape)\n",
    "#print(text_list.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "print(len(text_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
       "                ('multinomialnb', MultinomialNB())])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "model = make_pipeline(TfidfVectorizer(), MultinomialNB())\n",
    "model.fit(text_list, text_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<bound method Pipeline.get_params of Pipeline(steps=[('tfidfvectorizer', TfidfVectorizer()),\n",
      "                ('multinomialnb', MultinomialNB())])>\n"
     ]
    }
   ],
   "source": [
    "test='Một nguồn tin của ET cho biết người thân dành nhiều thời gian bên Will Smith trong giai đoạn khó khăn. \"\"Họ cùng cố gắng và đoàn kết để vượt qua thử thách này.'\n",
    "print(model.predict([test]))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "ef7f9a8012d9131766e31894c279374cc63c73121ed4db3b9e67a294a4bf0e74"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
